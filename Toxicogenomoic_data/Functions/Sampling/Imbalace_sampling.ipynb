{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicology=pd.read_csv('Data_Grey_modules.csv')\n",
    "pathology=pd.read_csv('Pathological_finding_external_traits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unuseful columns\n",
    "\n",
    "toxicology=toxicology.drop(columns='Unnamed: 0')\n",
    "toxicology=toxicology.drop_duplicates('Gene')\n",
    "toxicology=toxicology.T\n",
    "toxicology.columns=toxicology.iloc[1]\n",
    "toxicology= toxicology.iloc[2:]\n",
    "\n",
    "pathology=pathology.drop(columns='Unnamed: 0')\n",
    "\n",
    "rows=toxicology.index\n",
    "toxicology = toxicology.reset_index(drop=True)\n",
    "pathology =pathology.reset_index(drop=True)\n",
    "\n",
    "# Step 5: Merge the Toxicology and Pathology dataframes based on their row indices\n",
    "Data = pd.merge(pathology, toxicology, left_index=True, right_index=True, how='outer')\n",
    "Data.index=rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLSMOTE(x, y, k_neighbors=5, criterion_rate=1.2, maxstep=600):\n",
    "    \"\"\"\n",
    "    Give the augmented data using MLSMOTE algorithm\n",
    "    Synthetic Minority Over-sampling Technique on multi-label dataset\n",
    "    resample only the samples with minority classes\n",
    "\n",
    "    Feature Vector Generation: (new_X)\n",
    "    it uses the same SMOTE algorithm to generate the feature vector for the newly generated data.\n",
    "    it finds the 5 nearest neighbors to the sample points. then draws a line to each of them.\n",
    "    Then create samples on the lines with class == minority class.\n",
    "\n",
    "    Every label whose IRPL(l) > MIR is considered as a tail label and all the instance of\n",
    "    the data which contain that label is considered as minority instance data.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pandas.DataFrame, feature vector dataframe\n",
    "    y : pandas.DataFrame, label set DataFrame\n",
    "        y(i,j)=0 if i-th sample don't have j-th label, else 1\n",
    "\n",
    "    k_neighbor: int, number of nearest neighbors\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_new : ndarray, shape (n_samples_new, n_features)\n",
    "            Synthetically generated samples.\n",
    "    y_new : ndarray, shape (n_samples_new, n_labels)\n",
    "            Target values for synthetic samples.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_labels = y.shape  # samples num, labels num\n",
    "\n",
    "    # computer k-nn, 5 nearest neighbor of all the instance(of each element in X)\n",
    "    neigh = NearestNeighbors(n_neighbors=k_neighbors, metric='euclidean', algorithm='auto')\n",
    "    neigh.fit(x)\n",
    "\n",
    "    x_new, y_new = x, y\n",
    "\n",
    "    full_label_name = y.columns.values.tolist()  # full set of labels names\n",
    "    rand_seed = 2  # Not actually random. Users would get the same result.\n",
    "    j = 0\n",
    "    while True:\n",
    "        # check the condition to terminate the current iteration\n",
    "        label_count = np.sum(y_new, axis=0)  # count the number of 1 in each column\n",
    "        print(label_count)\n",
    "        print(\"step-{}: num_majority / num_minority: {}\".format(j, np.max(label_count) / np.min(label_count)))\n",
    "        if np.max(label_count) / np.min(label_count) < criterion_rate:\n",
    "            break\n",
    "\n",
    "        irpl, mean_ir = get_IRPL_and_meanIR(y)  # calculate IR per label and meanIR\n",
    "        count = 0  # store label index\n",
    "\n",
    "        # search which label is majority or minority\n",
    "        for each_label in full_label_name:  # loop through labels\n",
    "            print(\"step \" + str(j) + \" loop labels: \" + str(each_label))\n",
    "            if irpl[count] > mean_ir:\n",
    "                # y.iloc[:, count] give tail label column of the given target dataframe.\n",
    "                # the index number of the tail label is [count]\n",
    "                # min_bag = get_all_instances_of_tail_label(each_label)  # return instances of tail label.\n",
    "                # minBag: bags of minority labels samples\n",
    "                min_bag_indx = (y.iloc[:, count] == 1)  # give the Boolean index of the tail label instances\n",
    "                minority_x, minority_y = x[min_bag_indx], y[min_bag_indx]  # bags of minority label samples\n",
    "                distances, indices = neigh.kneighbors(minority_x, k_neighbors)  # neigh instances indices and distances\n",
    "                # print(indices)\n",
    "                # print(distances)\n",
    "\n",
    "                for neighIndx in indices:\n",
    "                    print(\"neighIndx:\" + str(neighIndx))  # distance smallest items\n",
    "                    # A for loop is used for iterating over sample in min_bag\n",
    "                    # para neighIndx contains reference data point and neighbour data points\n",
    "                    rand_seed = rand_seed + j + count + 2  # change random seed\n",
    "                    random.seed(rand_seed)\n",
    "                    np.random.seed(rand_seed)\n",
    "\n",
    "                    # find out reference data point and neighbour data points\n",
    "                    reference = neighIndx[0]\n",
    "                    print(\"reference point:\" + str(reference))\n",
    "                    neighbours = np.random.choice(neighIndx[1:], 1)[0]  # get rand neighbour, [0] convert list to int\n",
    "                    print(\"neighbours point:\" + str(neighbours))\n",
    "\n",
    "                    # ## Synthetic Data, feature set and label set generation\n",
    "                    # neighIndx[0] is sample(first element in indices), reference is refNeigh, neighbours is neighbours\n",
    "                    if np.all(y.iloc[neighIndx[0]] == y.iloc[neighbours]):\n",
    "                        print(\"method 1\")\n",
    "                        # sample label set == neighbour label set\n",
    "                        ratio = random.random()  # generates a random float uniformly in the semi-open range [0.0, 1.0)\n",
    "                        # Feature Vector Generation\n",
    "                        temp_x = [(1 - ratio) * x.iloc[neighIndx[0]] + ratio * x.iloc[neighbours]]\n",
    "                        # Label Set Generation\n",
    "                        temp_y = [y.iloc[neighIndx[0]]]  # same label set\n",
    "                    elif (np.sum((y.iloc[neighIndx[0]] == y.iloc[neighbours]))).astype(int) != 0:\n",
    "                        print(\"method 2\")\n",
    "                        # sample label set != neighbour label set\n",
    "                        c = (np.sum((y.iloc[neighIndx[0]] == y.iloc[neighbours]))).astype(float) / n_labels\n",
    "                        ratio = random.random() * c\n",
    "                        # Feature Vector Generation\n",
    "                        temp_x = [(1 - ratio) * x.iloc[neighIndx[0]] + ratio * x.iloc[neighbours]]\n",
    "                        # Label Set Generation\n",
    "                        temp_y = (1 - ratio) * y.iloc[neighIndx[0]] + ratio * y.iloc[neighbours]\n",
    "                        temp_y = [(temp_y > 0.5).astype(int)]\n",
    "                    else:\n",
    "                        print(\"method 3\")\n",
    "                        # reference label set == neighbour label set == all labels are 0\n",
    "                        ratio = random.random()\n",
    "                        # Feature Vector Generation\n",
    "                        temp_x = [(1 - ratio) * x.iloc[neighIndx[0]] + ratio * x.iloc[neighbours]]\n",
    "                        # Label Set Generation\n",
    "                        nn_df = y[y.index.isin(neighIndx)]  # all neigh samples labels set\n",
    "                        ser = nn_df.sum(axis=0, skipna=True)  # the number of occurrences of each label\n",
    "                        # temp_y = np.array([1 if val > 2 else 0 for val in ser])  # label_generation_method = \"Ranking\"\n",
    "                        temp_y = np.array([1 if val > 0 else 0 for val in ser])  # label_generation_method = \"Union\"\n",
    "                        temp_y = [temp_y]\n",
    "\n",
    "                    # print(\"Label Set Generation: \\n\"+str(temp_y))\n",
    "\n",
    "                    temp_x = np.array(temp_x)  # shape:(1,feat_num)\n",
    "                    temp_y = np.array(temp_y)  # shape:(1,feat_num)\n",
    "\n",
    "                    x_new = np.concatenate((x_new, temp_x))\n",
    "                    y_new = np.concatenate((y_new, temp_y))\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "        j += 1\n",
    "        if j > maxstep:\n",
    "            break\n",
    "\n",
    "    x_new, y_new = shuffle(x_new, y_new, random_state=12)\n",
    "    return x_new, y_new\n",
    "\n",
    "\n",
    "def singleLabelSMOTE(X, k_neighbors=5, rate=3):\n",
    "    \"\"\"\n",
    "    Synthetic Minority Over-sampling Technique on single-label dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "\n",
    "    k_neighbors : int\n",
    "\n",
    "    rate : float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : ndarray\n",
    "\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    N_new = int(N * rate)\n",
    "\n",
    "    # computer k-nn\n",
    "    X = shuffle(X)\n",
    "    neigh = NearestNeighbors(n_neighbors=k_neighbors)\n",
    "    neigh.fit(X)\n",
    "\n",
    "    X_new = X\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    for x in X:\n",
    "        knn = neigh.kneighbors(x.reshape(1, -1), k_neighbors)\n",
    "        for _ in range(int(np.floor(rate))):\n",
    "            m = random.randint(1, k_neighbors - 1)\n",
    "            r = random.random()\n",
    "            k = knn[1][0, m]\n",
    "            sx = [(1 - r) * x + r * X[k]]\n",
    "            X_new = np.concatenate((X_new, sx))\n",
    "            j += 1\n",
    "\n",
    "    if j >= N_new:\n",
    "        return X_new\n",
    "    else:\n",
    "        X = shuffle(X)\n",
    "        for x in X:\n",
    "            knn = neigh.kneighbors(x.reshape(1, -1), k_neighbors)\n",
    "            m = random.randint(1, k_neighbors - 1)\n",
    "            r = random.random()\n",
    "            k = knn[1][0, m]\n",
    "            sx = [(1 - r) * x + r * X[k]]\n",
    "            X_new = np.concatenate((X_new, sx))\n",
    "            j += 1\n",
    "            if j >= N_new:\n",
    "                break\n",
    "        return X_new\n",
    "\n",
    "\n",
    "def get_IRPL_and_meanIR(label):\n",
    "    \"\"\"\n",
    "       Imbalance ratio per label(irpl): It’s calculated individually for each label.The higher is the IRPL the larger\n",
    "                                      would be the imbalance, allowing to know which labels are in minority or majority.\n",
    "       Mean Imbalance ratio(mir): It is defined as the average of IRPL of all the labels.\n",
    "\n",
    "       abbreviation:\n",
    "       IR: imbalance ratio\n",
    "       IRPL/IRL: imbalance ratio per label\n",
    "       mir/mean_IR: mean imbalance ratio\n",
    "\n",
    "       args\n",
    "       y: pandas.DataFrame, the target vector dataframe\n",
    "    \"\"\"\n",
    "    columns = label.columns\n",
    "    n = len(columns)  # labels num\n",
    "    irpl = np.zeros(n)\n",
    "    for column in range(n):\n",
    "        irpl[column] = label[columns[column]].value_counts()[1]\n",
    "    print(\"per label num: \" + str(irpl))  # returns object containing counts of unique values\n",
    "    irpl = max(irpl) / irpl\n",
    "    print(\"Imbalance ratio per label(irpl): \" + str(irpl))\n",
    "    print(\"Max Imbalance ratio(MaxIR): \" + str(max(irpl)))\n",
    "    mir = np.average(irpl)\n",
    "    print(\"Mean Imbalance ratio(mir): \" + str(mir))\n",
    "    return irpl, mir\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "        main function to use the MLSMOTE\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # ------------------------GET LABELS AND FEATURES-----------------------------#\n",
    "    # extract labels from data, split the features-X and labels-y\n",
    "    X = Data.iloc[:, 8:]  # features\n",
    "    Y = Data.iloc[:, :8]  # labels\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    # --------------------------MLSMOTE ALGORITHM----------------------------------#\n",
    "    X_new, Y_new = MLSMOTE(X, Y)\n",
    "    print(X_new.shape)\n",
    "    print(Y_new.shape)\n",
    "    X_new = pd.DataFrame(X_new, columns=X.columns)\n",
    "    Y_new = pd.DataFrame(Y_new, columns=Y.columns)\n",
    "\n",
    "    result = pd.concat([Y_new, X_new], axis=1)  # down rows (axis=0) or along columns (axis=1)\n",
    "    pd_data = pd.DataFrame(result)\n",
    "    pd_data.to_csv('kidney mlsmote result.csv', index=False)\n",
    "\n",
    "    # --------------------------IMBALANCE COMPARISON----------------------------------#\n",
    "    print(\"--------Original Dataset---------\")\n",
    "    get_IRPL_and_meanIR(Y)\n",
    "    print(\"--------Applying MLSMOTE---------\")\n",
    "    get_IRPL_and_meanIR(Y_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
